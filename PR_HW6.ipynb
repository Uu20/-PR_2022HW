{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 樣形式別 作業6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B0829015 黃聖文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介紹keras有2種模型：\n",
    "1. Sequential 模型\n",
    "2. 函數式的API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential模型是我們前面常用的，用來建立像是fully convolutional networks會很方便"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函數式API使用模型時，更加自由，適合處理多輸入多輸出的模型\n",
    "可以將一曾網路模型看成一個函式，透過建立一個張量來使用他。\n",
    "而他在調用模型時，不只使用它的結構，還有他的權重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.27834588,  0.00883538,  0.18865758,  0.02021629,  0.09515035,\n",
       "          0.12712955,  0.26824808,  0.04851577,  0.2611891 ,  0.17604464,\n",
       "          0.03845611,  0.06290945,  0.26459956, -0.2939833 , -0.23019892,\n",
       "          0.0670417 , -0.03494126, -0.1001115 ,  0.15413278, -0.2579236 ,\n",
       "         -0.1433148 , -0.24178758, -0.0746374 ,  0.11718631,  0.2927099 ,\n",
       "         -0.1916434 ,  0.2607947 ,  0.13457367, -0.24450393, -0.22165214,\n",
       "          0.24083245, -0.1453544 ,  0.26219618, -0.13407081, -0.23250887,\n",
       "         -0.23186138, -0.02079222,  0.25188047,  0.21885598, -0.28029573,\n",
       "         -0.19938275, -0.27798778, -0.20123756,  0.19530466,  0.01725629,\n",
       "         -0.19564892,  0.03188723, -0.29294705, -0.27903736,  0.19961348,\n",
       "          0.18026713, -0.12663727,  0.27589238,  0.28521287,  0.2816065 ,\n",
       "          0.27910894,  0.16029093, -0.167699  , -0.28055093, -0.10987176,\n",
       "         -0.1581278 ,  0.11166415,  0.12701496,  0.13585073],\n",
       "        [ 0.13515529,  0.03896546,  0.14771515, -0.11513606, -0.1696497 ,\n",
       "          0.27101213,  0.19096524, -0.28404447,  0.02064288,  0.10450244,\n",
       "         -0.04595044, -0.11601606,  0.11523145, -0.0065985 , -0.24140973,\n",
       "          0.06569856, -0.02133253,  0.15641013, -0.25144374, -0.09927453,\n",
       "          0.00306103,  0.21199495, -0.229429  , -0.23414943, -0.044857  ,\n",
       "          0.28990293, -0.1998358 ,  0.29055935,  0.19872144, -0.2325638 ,\n",
       "          0.04193661,  0.2710486 , -0.2681763 ,  0.12491372,  0.03714141,\n",
       "         -0.07806793, -0.0147759 , -0.28635418,  0.20525485,  0.25333345,\n",
       "          0.08368611, -0.03951856,  0.13209462, -0.02009457,  0.01911455,\n",
       "          0.26139796,  0.17903018,  0.27520454,  0.1349979 ,  0.17644063,\n",
       "         -0.20684876,  0.00621778,  0.17716372, -0.26217803,  0.11877128,\n",
       "          0.11887753,  0.02288389, -0.26680365,  0.01367274, -0.29898632,\n",
       "          0.00462344, -0.18540828, -0.06691954, -0.2628552 ],\n",
       "        [-0.1560471 , -0.19300458,  0.01039076,  0.06653169,  0.18725389,\n",
       "         -0.11846898, -0.20939921,  0.03526717, -0.1647739 , -0.24143934,\n",
       "          0.10676536, -0.1815491 ,  0.24520129,  0.01914024, -0.14210974,\n",
       "          0.01630402,  0.12872654,  0.02994558,  0.07846677,  0.02867138,\n",
       "          0.03422022, -0.08231923,  0.26621038,  0.16909626,  0.18199643,\n",
       "         -0.20084438,  0.11638978,  0.00245091, -0.27010518,  0.1576542 ,\n",
       "         -0.08762413,  0.14833629,  0.12797111,  0.05861148, -0.01514721,\n",
       "          0.04728115,  0.15522626, -0.07221702,  0.08570567,  0.08133394,\n",
       "         -0.14652222,  0.2908414 , -0.25742066,  0.24068004,  0.01723582,\n",
       "         -0.09585862, -0.10664208, -0.27156073, -0.24372596,  0.13069293,\n",
       "          0.22828358, -0.02985406,  0.274077  ,  0.07724801, -0.07448836,\n",
       "          0.14001462, -0.23499802,  0.13411555, -0.22530547,  0.03022155,\n",
       "         -0.03117782,  0.13782668, -0.20881438,  0.00433263]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-1.43071726e-01, -4.28346097e-02,  1.28630102e-01,\n",
       "          1.75939411e-01,  1.73965931e-01, -6.94118887e-02,\n",
       "         -4.26858664e-02, -8.64303261e-02,  4.08226550e-02,\n",
       "         -1.19972616e-01],\n",
       "        [-2.45126933e-01, -2.42070764e-01, -2.82731086e-01,\n",
       "         -1.26219973e-01, -1.95942312e-01, -1.86328068e-01,\n",
       "          8.76530707e-02,  3.30537558e-03,  2.09147424e-01,\n",
       "          2.48985559e-01],\n",
       "        [ 2.17206508e-01,  1.68788999e-01, -8.67685378e-02,\n",
       "          1.00717247e-01,  2.60810643e-01, -1.44364268e-01,\n",
       "         -1.47218466e-01,  2.73172349e-01, -1.74122959e-01,\n",
       "         -7.06729889e-02],\n",
       "        [-1.85993016e-02, -1.58603460e-01,  2.21496791e-01,\n",
       "          5.91756999e-02,  8.87242258e-02, -1.13765657e-01,\n",
       "          4.10819948e-02,  2.50984281e-01, -1.10843778e-03,\n",
       "         -2.72848308e-02],\n",
       "        [-1.26271218e-01,  2.78288275e-01, -1.45203248e-01,\n",
       "          6.72530234e-02,  1.97964907e-03, -1.28547132e-01,\n",
       "         -2.51721740e-01,  1.76730722e-01, -1.79887027e-01,\n",
       "          2.14212000e-01],\n",
       "        [ 1.61493689e-01, -4.93505597e-03,  7.55447745e-02,\n",
       "          7.97906518e-03,  1.43653542e-01,  5.43953776e-02,\n",
       "          1.05364650e-01,  8.68838131e-02, -1.95922419e-01,\n",
       "         -1.54568344e-01],\n",
       "        [-1.37681663e-02, -2.30430230e-01,  2.79030293e-01,\n",
       "         -1.42818704e-01, -2.33731747e-01, -1.54086530e-01,\n",
       "          1.58201963e-01,  1.56990886e-02, -2.70904481e-01,\n",
       "         -7.98263401e-02],\n",
       "        [ 3.50025296e-02,  1.17111355e-01, -2.72216767e-01,\n",
       "         -7.31286108e-02, -2.79272676e-01,  2.34749824e-01,\n",
       "          8.62785876e-02,  2.26509362e-01, -2.35684097e-01,\n",
       "          1.21310562e-01],\n",
       "        [ 2.74540633e-01, -1.59000203e-01,  8.20848048e-02,\n",
       "         -7.85061717e-02, -2.70521909e-01,  1.27025753e-01,\n",
       "         -4.02130783e-02, -2.77347863e-02, -3.16759646e-02,\n",
       "          5.25071025e-02],\n",
       "        [-2.70264447e-02,  4.54692543e-02,  6.91293478e-02,\n",
       "          1.45757824e-01, -1.63079590e-01, -1.98906824e-01,\n",
       "         -1.12698361e-01,  2.52771407e-01, -2.53622890e-01,\n",
       "         -6.38762861e-02],\n",
       "        [-5.74622601e-02,  1.89472407e-01, -8.91221166e-02,\n",
       "         -1.03057712e-01,  1.85799271e-01, -1.85305178e-02,\n",
       "          4.36063111e-02,  2.14785397e-01, -2.77580351e-01,\n",
       "          2.38526672e-01],\n",
       "        [-2.19155148e-01,  1.98369831e-01, -1.55158639e-01,\n",
       "         -4.01328206e-02,  1.46542281e-01,  2.31599420e-01,\n",
       "          1.26833618e-02,  2.34452337e-01,  1.32149726e-01,\n",
       "         -1.68958247e-01],\n",
       "        [ 1.45544320e-01,  2.71869093e-01, -1.83936268e-01,\n",
       "         -7.76115358e-02,  2.66194910e-01, -1.04134381e-02,\n",
       "          1.98466092e-01,  1.14407390e-01, -2.41000965e-01,\n",
       "         -9.62485671e-02],\n",
       "        [ 1.84525877e-01, -1.31999552e-02, -2.29559213e-01,\n",
       "         -2.82379687e-01, -7.02609122e-02,  2.26766437e-01,\n",
       "          3.49395871e-02,  2.74971753e-01,  1.81001157e-01,\n",
       "          1.96385086e-01],\n",
       "        [ 3.63476574e-02,  2.14260340e-01,  1.44231290e-01,\n",
       "          1.83191329e-01,  1.52523994e-01,  1.87307984e-01,\n",
       "         -1.66628093e-01,  2.15376616e-02,  1.96924508e-02,\n",
       "          1.07249379e-01],\n",
       "        [-1.15218684e-01,  1.20147020e-01,  6.37787282e-02,\n",
       "          1.67706311e-01, -1.90689564e-02, -6.61979467e-02,\n",
       "          1.55558646e-01, -8.29880685e-02,  2.52731472e-01,\n",
       "         -6.89269602e-02],\n",
       "        [ 1.29071444e-01, -2.22064555e-02, -2.84649760e-01,\n",
       "         -3.77390534e-02, -2.67666370e-01, -1.68405563e-01,\n",
       "         -2.61285007e-01, -6.07207417e-03,  7.91621804e-02,\n",
       "         -3.84413749e-02],\n",
       "        [ 1.55110985e-01,  1.80917650e-01,  2.28483766e-01,\n",
       "         -1.28056645e-01,  8.40932429e-02,  1.40518546e-01,\n",
       "          3.36375833e-03,  1.29581898e-01, -3.60526294e-02,\n",
       "         -2.03625247e-01],\n",
       "        [-5.32911569e-02, -1.63543001e-01,  8.26926827e-02,\n",
       "         -1.26656428e-01,  1.87940001e-02,  2.45217353e-01,\n",
       "          1.48582429e-01, -5.61190099e-02,  1.60395801e-01,\n",
       "         -2.23497808e-01],\n",
       "        [ 2.21331447e-01,  2.51105279e-01, -2.63303608e-01,\n",
       "         -1.92535907e-01, -2.83595175e-01,  8.45094621e-02,\n",
       "          7.68817365e-02, -1.20544299e-01,  1.44174039e-01,\n",
       "          1.99456930e-01],\n",
       "        [ 9.58818495e-02,  1.30339622e-01, -2.38072574e-02,\n",
       "          2.54523784e-01, -5.54075986e-02, -2.25743443e-01,\n",
       "          2.28757590e-01, -3.87495160e-02, -1.39034301e-01,\n",
       "         -6.57690316e-02],\n",
       "        [-2.14375958e-01,  3.15084159e-02, -2.23436773e-01,\n",
       "          2.11219788e-02,  2.42041647e-02,  1.23482823e-01,\n",
       "          4.52136397e-02,  1.22346967e-01,  9.87892449e-02,\n",
       "          1.64477497e-01],\n",
       "        [-2.54125088e-01,  7.80728459e-02, -2.13244259e-02,\n",
       "         -2.35915184e-02, -1.02426276e-01, -2.11889520e-01,\n",
       "         -2.82446712e-01, -2.51953244e-01,  3.30457389e-02,\n",
       "         -2.81488180e-01],\n",
       "        [ 6.36583567e-03,  8.64130855e-02, -2.21913218e-01,\n",
       "         -1.43562362e-01,  6.03237152e-02,  1.40507221e-02,\n",
       "          2.46126145e-01, -2.05016434e-01,  4.22033668e-03,\n",
       "         -5.38696349e-02],\n",
       "        [ 1.42931283e-01,  9.92657542e-02, -2.48873234e-03,\n",
       "          1.34797543e-01,  1.25293285e-01,  4.59858775e-02,\n",
       "          1.22646749e-01,  2.09812731e-01,  7.73239434e-02,\n",
       "          1.05046988e-01],\n",
       "        [-1.05002731e-01, -8.07200372e-02, -2.89809704e-02,\n",
       "          2.35148042e-01,  9.60420668e-02, -2.64981568e-01,\n",
       "          2.66226321e-01, -1.73399270e-01,  1.73702240e-02,\n",
       "         -1.81094632e-01],\n",
       "        [-9.69755948e-02,  2.57503897e-01, -1.71151876e-01,\n",
       "         -9.32444781e-02,  2.23268479e-01,  5.29043972e-02,\n",
       "          1.51729286e-01, -1.25013039e-01,  2.06278890e-01,\n",
       "         -2.79077649e-01],\n",
       "        [ 2.38583714e-01,  5.93693256e-02,  2.20108122e-01,\n",
       "          7.41671920e-02,  2.63231128e-01,  6.99769258e-02,\n",
       "         -1.73999012e-01, -2.01110706e-01,  2.53585249e-01,\n",
       "          1.53118581e-01],\n",
       "        [ 1.88370109e-01, -1.72510147e-02,  2.36094683e-01,\n",
       "         -2.81483144e-01,  1.03542775e-01, -7.25807399e-02,\n",
       "         -2.35165894e-01,  2.81353980e-01, -2.31728882e-01,\n",
       "         -9.64354724e-02],\n",
       "        [-1.41739845e-04, -1.79888785e-01,  5.24529219e-02,\n",
       "          1.17198825e-02,  2.52660960e-01,  6.33712411e-02,\n",
       "         -1.39645502e-01, -1.81835920e-01, -3.54418308e-02,\n",
       "         -1.45559669e-01],\n",
       "        [ 2.44494408e-01,  9.85157192e-02,  1.51053578e-01,\n",
       "          9.56988633e-02, -1.62810341e-01,  1.18790179e-01,\n",
       "         -2.46294752e-01,  1.17765337e-01, -1.04059413e-01,\n",
       "          9.48219597e-02],\n",
       "        [ 2.42093533e-01, -2.29648769e-01, -2.76500583e-01,\n",
       "         -5.47365099e-02, -7.64321685e-02,  6.39419854e-02,\n",
       "         -1.11046016e-01,  5.25027514e-03, -2.55902410e-02,\n",
       "          1.54591560e-01],\n",
       "        [-1.76279664e-01, -3.29352915e-02, -1.63335800e-02,\n",
       "          9.64785814e-02, -1.51492223e-01,  3.47131193e-02,\n",
       "          3.96719873e-02,  1.69426054e-01, -2.25496799e-01,\n",
       "          5.95272481e-02],\n",
       "        [-2.21006751e-01, -2.76472926e-01,  1.41385972e-01,\n",
       "         -2.38675430e-01, -1.20781645e-01,  6.24156594e-02,\n",
       "         -2.01225102e-01,  2.26764292e-01, -1.92242026e-01,\n",
       "          2.35223562e-01],\n",
       "        [-1.84965879e-01, -2.37546906e-01, -4.92560863e-03,\n",
       "          9.76603925e-02, -3.24726105e-03, -1.28447413e-01,\n",
       "          3.92262340e-02, -2.13131219e-01,  2.51803368e-01,\n",
       "         -1.48031026e-01],\n",
       "        [-3.69833112e-02,  2.74256736e-01, -1.29213259e-01,\n",
       "         -2.14371204e-01,  2.29005605e-01, -1.41293988e-01,\n",
       "          2.17464477e-01,  2.14412004e-01,  2.21779257e-01,\n",
       "         -7.77879059e-02],\n",
       "        [-2.69854367e-02, -1.33636579e-01,  1.53878659e-01,\n",
       "          1.98516548e-02, -1.14940196e-01, -1.69288188e-01,\n",
       "          2.41093636e-02, -2.01981038e-01, -6.55883700e-02,\n",
       "          1.02068305e-01],\n",
       "        [ 1.56688690e-02,  1.51564389e-01,  1.45337671e-01,\n",
       "          2.62594223e-03, -6.32641315e-02,  2.52185464e-02,\n",
       "          2.49122113e-01, -2.28530973e-01, -2.21640155e-01,\n",
       "          2.14626253e-01],\n",
       "        [ 1.26212835e-04,  2.82242924e-01,  2.71296710e-01,\n",
       "          1.04367912e-01, -1.56538621e-01, -1.57579690e-01,\n",
       "         -2.11700648e-01,  7.25349188e-02,  7.01745450e-02,\n",
       "         -1.42476827e-01],\n",
       "        [-2.37393349e-01, -1.85274154e-01,  2.38710612e-01,\n",
       "         -1.09180763e-01,  2.07210809e-01, -2.62471080e-01,\n",
       "         -2.71223068e-01,  2.59067088e-01, -2.75746524e-01,\n",
       "         -3.09367180e-02],\n",
       "        [-8.93368572e-02, -3.98191810e-02,  9.35953856e-02,\n",
       "         -2.77270973e-01, -1.56865716e-02, -2.52250373e-01,\n",
       "         -8.29350501e-02, -1.44288570e-01, -1.47061944e-02,\n",
       "         -1.03663355e-01],\n",
       "        [-5.82639575e-02, -5.00546098e-02,  1.81056291e-01,\n",
       "         -9.12204385e-03, -3.48206460e-02,  1.17974877e-02,\n",
       "          1.14219069e-01,  3.33987176e-02, -1.39510676e-01,\n",
       "         -1.58577934e-01],\n",
       "        [ 4.91721928e-02,  1.21668130e-01,  9.99688208e-02,\n",
       "         -2.04644322e-01, -1.13268360e-01,  1.42845392e-01,\n",
       "          4.28058803e-02, -2.82180578e-01,  3.89750600e-02,\n",
       "         -2.24292174e-01],\n",
       "        [ 6.13174736e-02, -1.87696040e-01,  2.74058789e-01,\n",
       "          1.33924752e-01,  1.05344296e-01, -6.00798577e-02,\n",
       "          9.57911313e-02, -2.13976771e-01,  1.63532466e-01,\n",
       "         -1.03846043e-01],\n",
       "        [-1.57476440e-01, -8.90332609e-02, -2.36494154e-01,\n",
       "         -7.26097375e-02,  2.59876341e-01, -1.77469701e-01,\n",
       "          1.59987122e-01,  2.19116807e-02, -2.67457664e-01,\n",
       "          1.54759109e-01],\n",
       "        [-6.00598305e-02, -1.55150279e-01,  1.80554450e-01,\n",
       "         -6.88496232e-03, -1.25811145e-01, -2.01974332e-01,\n",
       "          1.17424399e-01,  1.34958655e-01,  1.20541990e-01,\n",
       "         -8.01686347e-02],\n",
       "        [-1.69209152e-01,  6.06524348e-02, -2.52454996e-01,\n",
       "         -1.94762409e-01,  1.26019299e-01,  1.50171041e-01,\n",
       "         -1.66586608e-01,  4.10214961e-02, -2.40141153e-01,\n",
       "         -2.10171193e-01],\n",
       "        [-1.13141268e-01, -1.65251911e-01, -1.64809197e-01,\n",
       "          9.66988206e-02,  1.55613750e-01,  1.51412517e-01,\n",
       "          5.14423847e-02,  2.05281466e-01, -2.21369624e-01,\n",
       "         -7.61172175e-03],\n",
       "        [ 1.56078726e-01,  2.70427734e-01, -1.02409706e-01,\n",
       "         -1.65519327e-01, -2.26078331e-01,  1.94915563e-01,\n",
       "          1.46187305e-01, -1.42650142e-01,  3.88387144e-02,\n",
       "         -1.74850672e-01],\n",
       "        [ 2.25984722e-01, -2.29996890e-01, -5.39707839e-02,\n",
       "          8.80584419e-02,  2.82928437e-01, -2.03086883e-01,\n",
       "         -6.77838922e-03, -2.46200800e-01, -1.71376452e-01,\n",
       "         -4.18076515e-02],\n",
       "        [-2.70261079e-01, -4.04585600e-02, -1.84252903e-01,\n",
       "          2.46483892e-01, -2.62668729e-03, -9.50019211e-02,\n",
       "         -1.62026554e-01,  1.86351269e-01, -1.78520381e-02,\n",
       "          1.12348408e-01],\n",
       "        [ 3.34164202e-02, -2.34730333e-01,  1.87903941e-02,\n",
       "         -2.28029341e-01,  2.82143325e-01, -4.74760532e-02,\n",
       "         -3.72742265e-02,  2.25495785e-01, -1.97581232e-01,\n",
       "         -2.82401949e-01],\n",
       "        [ 1.71037674e-01,  9.67921615e-02, -1.61618471e-01,\n",
       "         -7.27882832e-02, -1.86685920e-01, -1.45829663e-01,\n",
       "          2.32616693e-01, -2.44022578e-01, -1.20327741e-01,\n",
       "          1.44963533e-01],\n",
       "        [-1.35908082e-01, -1.44556195e-01,  9.38753188e-02,\n",
       "          1.08732820e-01,  2.05617517e-01,  2.39897221e-01,\n",
       "         -1.90991431e-01,  1.32966250e-01,  9.14677680e-02,\n",
       "          1.20665610e-01],\n",
       "        [ 1.37543380e-02,  1.09353870e-01, -1.61526501e-01,\n",
       "         -2.00538546e-01,  3.33050787e-02, -2.78931856e-02,\n",
       "         -1.65656999e-01,  8.26033950e-03,  2.10650742e-01,\n",
       "          8.63821805e-02],\n",
       "        [-7.46984035e-02, -1.26839727e-01,  4.35288548e-02,\n",
       "         -7.52747059e-04, -1.26348272e-01,  2.62193769e-01,\n",
       "          1.68583095e-01,  6.43415153e-02,  1.93537623e-01,\n",
       "         -4.14975286e-02],\n",
       "        [ 2.56423980e-01, -8.26615244e-02,  6.31447732e-02,\n",
       "         -1.63837850e-01, -2.63093770e-01, -4.64664698e-02,\n",
       "          2.59427637e-01, -1.64445728e-01, -1.40708104e-01,\n",
       "         -1.22424960e-02],\n",
       "        [-3.18679214e-03, -2.82360196e-01, -2.04439312e-01,\n",
       "          7.16000199e-02,  9.98102427e-02, -2.57415056e-01,\n",
       "         -2.24496588e-01,  4.88093197e-02, -2.16547400e-01,\n",
       "          1.57162309e-01],\n",
       "        [-1.43534601e-01, -2.24777788e-01, -1.67328089e-01,\n",
       "         -1.76980287e-01,  2.83299655e-01,  4.84054387e-02,\n",
       "          2.09700584e-01, -2.22358108e-03,  5.78926206e-02,\n",
       "          2.97377110e-02],\n",
       "        [ 2.52959877e-01, -8.74369740e-02,  8.90397131e-02,\n",
       "         -9.93072540e-02, -2.44157940e-01,  2.07217187e-01,\n",
       "         -2.59915888e-02, -2.23083496e-02, -2.32659981e-01,\n",
       "         -8.75286311e-02],\n",
       "        [ 4.50065136e-02,  2.52198130e-01, -7.97651112e-02,\n",
       "         -8.95123482e-02,  2.18638331e-01, -1.83701038e-01,\n",
       "         -4.71739471e-02,  2.20228583e-01,  2.64575154e-01,\n",
       "         -2.83260614e-01],\n",
       "        [-2.31912792e-01, -5.61511815e-02,  1.54837310e-01,\n",
       "         -2.47925580e-01,  7.13594258e-02, -1.11275911e-03,\n",
       "          1.53853744e-01,  3.16838324e-02,  2.67945379e-01,\n",
       "          1.70500964e-01],\n",
       "        [-2.08742619e-02,  1.28209531e-01, -1.15744069e-01,\n",
       "          1.90647244e-01, -2.01196373e-01,  1.17359489e-01,\n",
       "         -5.76818138e-02,  1.26786709e-01,  2.44799644e-01,\n",
       "          2.49528319e-01],\n",
       "        [ 6.92223310e-02,  1.99106902e-01, -1.03130937e-03,\n",
       "         -1.64682791e-01, -2.79621214e-01, -2.49187097e-01,\n",
       "          5.01559079e-02, -1.57867402e-01, -7.27863759e-02,\n",
       "         -3.79801989e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_first_layer (Dense)       (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "my_last_layer (Dense)        (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_input (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 10ms/step - loss: 31.8319 - priority_loss: 0.2981 - department_loss: 31.5338 - priority_mean_absolute_error: 0.4619 - department_accuracy: 0.2492\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 24.1014 - priority_loss: 0.3345 - department_loss: 23.7669 - priority_mean_absolute_error: 0.4986 - department_accuracy: 0.0977\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 10ms/step - loss: 46.0514 - priority_loss: 0.3345 - department_loss: 45.7169 - priority_mean_absolute_error: 0.4986 - department_accuracy: 0.2602\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 20.5224 - priority_loss: 0.3345 - department_loss: 20.1879 - priority_mean_absolute_error: 0.4986 - department_accuracy: 0.1141\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x2011310f0f0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x2011310f128>,\n",
       " <keras.engine.input_layer.InputLayer at 0x2011310f438>,\n",
       " <keras.layers.merge.Concatenate at 0x2011310f748>,\n",
       " <keras.layers.core.Dense at 0x2011310fa58>,\n",
       " <keras.layers.core.Dense at 0x2011310fba8>,\n",
       " <keras.layers.core.Dense at 0x2011310a7b8>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 10ms/step - loss: 38.8975 - output_1_loss: 0.3258 - output_2_loss: 38.5718 - output_1_mean_absolute_error: 0.4914 - output_2_accuracy: 0.2461\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 53.1565 - output_1_loss: 0.3345 - output_2_loss: 52.8220 - output_1_mean_absolute_error: 0.4986 - output_2_accuracy: 0.2734\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2948 - accuracy: 0.9129 - val_loss: 0.1450 - val_accuracy: 0.9579\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1640 - accuracy: 0.9533 - val_loss: 0.1301 - val_accuracy: 0.9637\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1399 - accuracy: 0.9630 - val_loss: 0.1163 - val_accuracy: 0.9712\n",
      "313/313 [==============================] - 0s 823us/step - loss: 0.1037 - accuracy: 0.9726\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2973 - accuracy: 0.9135 - rmse: 7.1837 - val_loss: 0.1602 - val_accuracy: 0.9532 - val_rmse: 7.3503\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1663 - accuracy: 0.9532 - rmse: 7.3554 - val_loss: 0.1293 - val_accuracy: 0.9674 - val_rmse: 7.4053\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1419 - accuracy: 0.9624 - rmse: 7.3883 - val_loss: 0.1086 - val_accuracy: 0.9713 - val_rmse: 7.4223\n",
      "313/313 [==============================] - 0s 876us/step - loss: 0.1014 - accuracy: 0.9724 - rmse: 7.4337\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2975 - accuracy: 0.9113 - val_loss: 0.1477 - val_accuracy: 0.9583\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1637 - accuracy: 0.9539 - val_loss: 0.1276 - val_accuracy: 0.9647\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1389 - accuracy: 0.9632 - val_loss: 0.1086 - val_accuracy: 0.9734\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1255 - accuracy: 0.9674 - val_loss: 0.1055 - val_accuracy: 0.9740\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1153 - accuracy: 0.9709 - val_loss: 0.1131 - val_accuracy: 0.9751\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1087 - accuracy: 0.9732 - val_loss: 0.1114 - val_accuracy: 0.9746\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1058 - accuracy: 0.9757 - val_loss: 0.1111 - val_accuracy: 0.9780\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0970 - accuracy: 0.9767 - val_loss: 0.1122 - val_accuracy: 0.9765\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0969 - accuracy: 0.9784 - val_loss: 0.1146 - val_accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201130b7438>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2902 - accuracy: 0.9146 - val_loss: 0.1492 - val_accuracy: 0.9560\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1625 - accuracy: 0.9539 - val_loss: 0.1228 - val_accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1377 - accuracy: 0.9628 - val_loss: 0.1054 - val_accuracy: 0.9735\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1221 - accuracy: 0.9681 - val_loss: 0.1147 - val_accuracy: 0.9703\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1141 - accuracy: 0.9707 - val_loss: 0.1122 - val_accuracy: 0.9748\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1122 - accuracy: 0.9716 - val_loss: 0.1046 - val_accuracy: 0.9766\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1039 - accuracy: 0.9756 - val_loss: 0.1118 - val_accuracy: 0.9754\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1023 - accuracy: 0.9761 - val_loss: 0.1069 - val_accuracy: 0.9777\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0976 - accuracy: 0.9780 - val_loss: 0.1160 - val_accuracy: 0.9789\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0985 - accuracy: 0.9790 - val_loss: 0.1126 - val_accuracy: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200cea65a20>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2963 - accuracy: 0.9123 - val_loss: 0.1543 - val_accuracy: 0.9567\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1676 - accuracy: 0.9536 - val_loss: 0.1250 - val_accuracy: 0.9669\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1402 - accuracy: 0.9616 - val_loss: 0.1062 - val_accuracy: 0.9731\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1253 - accuracy: 0.9679 - val_loss: 0.1129 - val_accuracy: 0.9735\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1138 - accuracy: 0.9704 - val_loss: 0.1110 - val_accuracy: 0.9746\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1115 - accuracy: 0.9725 - val_loss: 0.1158 - val_accuracy: 0.9741\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1055 - accuracy: 0.9742 - val_loss: 0.0999 - val_accuracy: 0.9779\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0999 - accuracy: 0.9765 - val_loss: 0.1094 - val_accuracy: 0.9755\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0956 - accuracy: 0.9776 - val_loss: 0.1136 - val_accuracy: 0.9779\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0956 - accuracy: 0.9791 - val_loss: 0.1140 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20119d661d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4862ce461d7ba48d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4862ce461d7ba48d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9146\n",
      "...loss: 0.2889\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9542\n",
      "...loss: 0.1639\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9636\n",
      "...loss: 0.1393\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9643\n",
      "...val_loss: 0.1433\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9643\n",
      "...val_loss: 0.1433\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2941\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1648\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201229c9b00>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2951 - sparse_categorical_accuracy: 0.9124\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1671 - sparse_categorical_accuracy: 0.9535\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1398 - sparse_categorical_accuracy: 0.9628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201231de828>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
